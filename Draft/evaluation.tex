\section{Evaluation}
\label{sec:evaluation}

We conducted an evaluation to assess the effectiveness of our approach. In our evaluation, we address two main research questions:

\begin{itemize}
	\item\textbf{RQ1}: What are the precision and recall of \tool\  in
	identifying temporal contraints from sentences written in natural language?
	%\item\textbf{RQ2}: What is the accuracy of our approach in inferring specifications from contract sentences in the API documents? 
	\item\textbf{RQ2}: How does our approach fares in comparison to previous NLP approaches?
\end{itemize}

\subsection{Subjects}
\label{sub:subject}

We used the API documents of the following two libraries as subjects for our evaluation. 
\begin{itemize}
	\item{Amazon S3}. \amazon\ provides a REST based web services interface that can be used to store and retrieve data on the web. Furthermore, \CodeIn{Amazon S3} also empowers a developer with rich set of API methods to access a highly scalable, reliable, secure, fast, inexpensive infrastructure. \CodeIn{Amazon S3} is reported to store more than 2 trillion objects as of April 2013 and gets over 1.1 million requests per second at peak time~\cite{amazons3stats}.

	\item{java.io}. \CodeIn{java.io} is a popular packacge in \CodeIn{Java} programming language that provides APIs for system input and output through data streams, serialization and the file system.
\end{itemize}
We chose \CodeIn{Amazon S3} and \CodeIn{java.io} APIs as our subjects because they are popular and contain decent documentation.

\subsection{Experimental Setup.} 
We apply our approach on the API documents of the two APIs.
To determine the precision and recall, 
two authors manually label each sentence in the API documentation as sentence containing 
temporal constraints or not. After the authors have classified all the sentences, they 
talk to each ther to reach a consensus on the sentences they classified differently. 
We use this classified scentes as the golden set for calculating precision and recall.

\CodeIn{cohen kappa} score of the two authors was 6.6 


\subsection{Summary}
\label{sub:summary}

\subsection{Threats to Validity}
\label{sub:threats_to_validity}
Threats to external validity primarily include the degree to which the subject documents used in our evaluations are representative of true practice. To minimize the threat, we used API documents of two representative commercial REST API: one dealing with online storage and the other \textbf{TBD}. The \amazon documents describe one of the most popularly used and online storage APIs. We also used the \textbf{TBD}. Furthermore, the difference in the functionalities provided by the two projects also address the issue of over fitting our approach to a particular type of API. The threat can be further reduced by evaluating our approach on more subjects. 

Threats to internal validity include the correctness of our implementation in extracting usage constraints and labelling a statement as a constraint statement. To reduce the threat, we manually inspected all the constraints inferred against the API method descriptions in our evaluation. Furthermore, we ensured that the results were individually verified and agreed
upon by two authors.




If any in-memory buffering is being done by the application (for example, by a BufferedOutputStream object), those buffers must be flushed into the FileDescriptor (for example, by invoking OutputStream.flush) before that data will be affected by sync.


If markposMM is -1MM (no mark has been set or the mark has been invalidated), an IOExceptionMM is thrown.